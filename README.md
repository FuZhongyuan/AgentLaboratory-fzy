# fzy Agent: Using LLM Agents as Research Assistants


<p align="center">
  <img src="media/AgentLabLogo.png" alt="Demonstration of the flow of AgentClinic" style="width: 99%;">
</p>

<p align="center">
    ã€English | <a href="readme/README-chinese.md">ä¸­æ–‡</a> | <a href="readme/README-japanese.md">æ—¥æœ¬èª</a> | <a href="readme/README-korean.md">í•œêµ­ì–´</a> | <a href="readme/README-filipino.md">Filipino</a> | <a href="readme/README-french.md">FranÃ§ais</a> | <a href="readme/README-slovak.md">SlovenÄina</a> | <a href="readme/README-portugese.md">PortuguÃªs</a> | <a href="readme/README-spanish.md">EspaÃ±ol</a> | <a href="readme/README-turkish.md">TÃ¼rkÃ§e</a> | <a href="readme/README-hindi.md">à¤¹à¤¿à¤‚à¤¦à¥€</a> | <a href="readme/README-bengali.md">à¦¬à¦¾à¦‚à¦²à¦¾</a> | <a href="readme/README-vietnamese.md">Tiáº¿ng Viá»‡t</a> | <a href="readme/README-russian.md">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> | <a href="readme/README-arabic.md">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> | <a href="readme/README-farsi.md">ÙØ§Ø±Ø³ÛŒ</a> | <a href="readme/README-italian.md">Italiano</a>ã€‘
</p>

<p align="center">
    ã€ğŸ“ <a href="https://arxiv.org/pdf/2501.04227">Paper</a> | ğŸŒ <a href="https://agentlaboratory.github.io/">Website</a> | ğŸŒ <a href="https://agentrxiv.github.io/">AgentRxiv Website</a> | ğŸ’» <a href="https://github.com/SamuelSchmidgall/AgentLaboratory">Software</a> | ğŸ“° <a href="https://agentlaboratory.github.io/#citation-ref">Citation</a>ã€‘
</p>

### News 
* [March/24/2025] ğŸ‰ ğŸŠ ğŸ‰ Now introducing **AgentRxiv**, a framework where autonomous research agents can upload, retrieve, and build on each other's research. This allows agents to make cumulative progress on their research.

## ğŸ“– Overview

- **fzy Agent** is an end-to-end autonomous research workflow meant to assist **you** as the human researcher toward **implementing your research ideas**. fzy Agent consists of specialized agents driven by large language models to support you through the entire research workflowâ€”from conducting literature reviews and formulating plans to executing experiments and writing comprehensive reports. 
- This system is not designed to replace your creativity but to complement it, enabling you to focus on ideation and critical thinking while automating repetitive and time-intensive tasks like coding and documentation. By accommodating varying levels of computational resources and human involvement, fzy Agent aims to accelerate scientific discovery and optimize your research productivity.
<p align="center">
  <img src="media/AgentLab.png" alt="Demonstration of the flow of AgentClinic" style="width: 99%;">
</p>

- fzy Agent also supports **AgentRxiv**, a framework where autonomous research agents can upload, retrieve, and build on each other's research. This allows agents to make cumulative progress on their research.

<p align="center">
  <img src="media/agentrxiv.png" alt="Demonstration of the flow of AgentClinic" style="width: 99%;">
</p>


### ğŸ”¬ How does fzy Agent work?

- fzy Agent consists of three primary phases that systematically guide the research process: (1) Literature Review, (2) Experimentation, and (3) Report Writing. During each phase, specialized agents driven by LLMs collaborate to accomplish distinct objectives, integrating external tools like arXiv, Hugging Face, Python, and LaTeX to optimize outcomes. This structured workflow begins with the independent collection and analysis of relevant research papers, progresses through collaborative planning and data preparation, and results in automated experimentation and comprehensive report generation. Details on specific agent roles and their contributions across these phases are discussed in the paper.

<p align="center">
  <img src="media/AgentLabWF.png" alt="Demonstration of the flow of AgentClinic" style="width: 99%;">
</p>


### ğŸ‘¾ Currently supported models

* **OpenAI**: o1, o1-preview, o1-mini, gpt-4o, o3-mini
* **DeepSeek**: deepseek-chat (deepseek-v3)

To select a specific llm set the flag `--llm-backend="llm_model"` for example `--llm-backend="gpt-4o"` or `--llm-backend="deepseek-chat"`. Please feel free to add a PR supporting new models according to your need!

## ğŸ–¥ï¸ Installation

### Python venv option

* We recommend using python 3.12

1. **Clone the GitHub Repository**: Begin by cloning the repository using the command:
```bash
git clone git@github.com:SamuelSchmidgall/AgentLaboratory.git
```

2. **Set up and Activate Python Environment**
```bash
python -m venv venv_agent_lab
```
- Now activate this environment:
```bash
source venv_agent_lab/bin/activate
```

3. **Install required libraries**
```bash
pip install -r requirements.txt
```

4. **Install pdflatex [OPTIONAL]**
```bash
sudo apt install pdflatex
```
- This enables latex source to be compiled by the agents.
- **[IMPORTANT]** If this step cannot be run due to not having sudo access, pdf compiling can be turned off via running fzy Agent via setting the `--compile-latex` flag to false: `--compile-latex "false"`



5. **Now run fzy Agent!**

`python ai_lab_repo.py --yaml-location "experiment_configs/MATH_agentlab.yaml"`


### Co-Pilot mode

To run fzy Agent in copilot mode, simply set the copilot-mode flag in your yaml config to `"true"`

-----
## Tips for better research outcomes


#### [Tip #1] ğŸ“ Make sure to write extensive notes! ğŸ“

**Writing extensive notes is important** for helping your agent understand what you're looking to accomplish in your project, as well as any style preferences. Notes can include any experiments you want the agents to perform, providing API keys, certain plots or figures you want included, or anything you want the agent to know when performing research.

This is also your opportunity to let the agent know **what compute resources it has access to**, e.g. GPUs (how many, what type of GPU, how many GBs), CPUs (how many cores, what type of CPUs), storage limitations, and hardware specs.

In order to add notes, you must modify the task_notes_LLM structure inside of `ai_lab_repo.py`. Provided below is an example set of notes used for some of our experiments. 


```
task-notes:
  plan-formulation:
    - 'You should come up with a plan for only ONE experiment aimed at maximizing performance on the test set of MATH using prompting techniques.'
    - 'Please use gpt-4o-mini for your experiments'
    - 'You must evaluate on the entire 500 test questions of MATH'
  data-preparation:
    - 'Please use gpt-4o-mini for your experiments'
    - 'You must evaluate on the entire 500 test questions of MATH'
    - 'Here is a sample code you can use to load MATH\nfrom datasets import load_dataset\nMATH_test_set = load_dataset("HuggingFaceH4/MATH-500")["test"]'
...
```

--------

#### [Tip #2] ğŸš€ Using more powerful models generally leads to better research ğŸš€

When conducting research, **the choice of model can significantly impact the quality of results**. More powerful models tend to have higher accuracy, better reasoning capabilities, and better report generation. If computational resources allow, prioritize the use of advanced models such as o1-(mini/preview) or similar state-of-the-art large language models.

However, **it's important to balance performance and cost-effectiveness**. While powerful models may yield better results, they are often more expensive and time-consuming to run. Consider using them selectivelyâ€”for instance, for key experiments or final analysesâ€”while relying on smaller, more efficient models for iterative tasks or initial prototyping.

When resources are limited, **optimize by fine-tuning smaller models** on your specific dataset or combining pre-trained models with task-specific prompts to achieve the desired balance between performance and computational efficiency.

-----

#### [Tip #3] âœ… You can load previous saves from checkpoints âœ…

**If you lose progress, internet connection, or if a subtask fails, you can always load from a previous state.** All of your progress is saved by default in the `state_saves` variable, which stores each individual checkpoint. 

-----


#### [Tip #4] ğŸˆ¯ If you are running in a language other than English ğŸˆ²

If you are running fzy Agent in a language other than English, no problem, just make sure to provide a language flag to the agents to perform research in your preferred language. Note that we have not extensively studied running fzy Agent in other languages, so be sure to report any problems you encounter.

For example, if you are running in Chinese set the language in the yaml:

`language:  "ä¸­æ–‡"`

----


#### [Tip #5] ğŸŒŸ There is a lot of room for improvement ğŸŒŸ

There is a lot of room to improve this codebase, so if you end up making changes and want to help the community, please feel free to share the changes you've made! We hope this tool helps you!


## ğŸ“œ License

Source Code Licensing: Our project's source code is licensed under the MIT License. This license permits the use, modification, and distribution of the code, subject to certain conditions outlined in the MIT License.

## ğŸ“¬ Contact

If you would like to get in touch, feel free to reach out to [sschmi46@jhu.edu](mailto:sschmi46@jhu.edu)

## Reference / Bibtex


### fzy Agent
```bibtex
@misc{schmidgall2025agentlaboratoryusingllm,
      title={fzy Agent: Using LLM Agents as Research Assistants}, 
      author={Samuel Schmidgall and Yusheng Su and Ze Wang and Ximeng Sun and Jialian Wu and Xiaodong Yu and Jiang Liu and Zicheng Liu and Emad Barsoum},
      year={2025},
      eprint={2501.04227},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2501.04227}, 
}
```

### AgentRxiv
```bibtex
@misc{schmidgall2025agentrxiv,
      title={AgentRxiv: Towards Collaborative Autonomous Research}, 
      author={Samuel Schmidgall and Michael Moor},
      year={2025},
      eprint={2503.18102},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2503.18102}, 
}
```

## ğŸ”„ å¤šç”¨æˆ·æ”¯æŒä¸æ–‡ä»¶ç®¡ç†

Agent Laboratoryç°å·²æ”¯æŒå¤šç”¨æˆ·å¹¶è¡Œä½¿ç”¨å’Œéš”ç¦»çš„æ–‡ä»¶ç®¡ç†ç³»ç»Ÿï¼Œç‰¹åˆ«é€‚åˆéœ€è¦æ„å»ºç½‘ç«™ç•Œé¢ä¾›å¤šäººä½¿ç”¨çš„åœºæ™¯ã€‚

### ä¸»è¦æ”¹è¿›ï¼š

1. **ç”¨æˆ·ä¼šè¯ç®¡ç†**ï¼š
   - ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºå”¯ä¸€çš„ä¼šè¯ID
   - æ‰€æœ‰ç”¨æˆ·æ•°æ®å…³è”åˆ°å…¶å”¯ä¸€æ ‡è¯†ç¬¦
   - è‡ªåŠ¨åˆ›å»ºç”¨æˆ·ä¸“å±æ•°æ®ç›®å½•

2. **å®‰å…¨çš„æ–‡ä»¶éš”ç¦»**ï¼š
   - æ¯ä¸ªç”¨æˆ·çš„æ•°æ®ã€ä»£ç å’Œç”Ÿæˆçš„å›¾ç‰‡ä¸¥æ ¼éš”ç¦»
   - é˜²æ­¢ç”¨æˆ·é—´æ•°æ®æ³„éœ²æˆ–å¹²æ‰°
   - è‡ªåŠ¨æƒé™æ£€æŸ¥ç¡®ä¿ç”¨æˆ·åªèƒ½è®¿é—®è‡ªå·±çš„æ•°æ®

3. **æ”¹è¿›çš„æ–‡ä»¶ç®¡ç†**ï¼š
   - æ‰€æœ‰ç”Ÿæˆçš„å›¾åƒå’Œæ–‡ä»¶ä¿å­˜åœ¨ç”¨æˆ·è‡ªå·±çš„ç›®å½•ä¸­
   - è§£å†³äº†ä¹‹å‰å›¾ç‰‡ç›´æ¥ä¿å­˜åœ¨æ ¹ç›®å½•çš„é—®é¢˜
   - ä¸ºmatplotlibç»˜å›¾æ·»åŠ è‡ªåŠ¨é‡å®šå‘åŠŸèƒ½

4. **ç ”ç©¶ä»»åŠ¡API**ï¼š
   - æ–°å¢APIç«¯ç‚¹ç”¨äºå¯åŠ¨ç ”ç©¶ä»»åŠ¡
   - æ”¯æŒè·Ÿè¸ªç ”ç©¶è¿›åº¦å’Œè·å–ç»“æœ
   - å¼‚æ­¥æ‰§è¡Œé•¿æ—¶é—´è¿è¡Œçš„å®éªŒ

5. **å®šæœŸæ¸…ç†æœºåˆ¶**ï¼š
   - è‡ªåŠ¨æ¸…ç†è¿‡æœŸçš„ç”¨æˆ·æ•°æ®å’Œä»»åŠ¡
   - ä¼˜åŒ–å­˜å‚¨ç©ºé—´ä½¿ç”¨
   - å¯é…ç½®çš„æ•°æ®ä¿ç•™ç­–ç•¥

### æŠ€æœ¯å®ç°ï¼š

- ä½¿ç”¨Flaskä¼šè¯ç®¡ç†ç”¨æˆ·çŠ¶æ€
- ä¿®æ”¹æ–‡ä»¶ç”Ÿæˆé€»è¾‘ï¼ŒåŒ…æ‹¬matplotlibç»˜å›¾å‡½æ•°
- æ·»åŠ ç”¨æˆ·æƒé™éªŒè¯å±‚
- å®ç°å¼‚æ­¥ä»»åŠ¡å¤„ç†æœºåˆ¶
- å»ºç«‹æ•°æ®åº“æ¨¡å‹è¿½è¸ªç”¨æˆ·å’Œä»»åŠ¡

### ä½¿ç”¨æ–¹æ³•ï¼š

ç”¨æˆ·ç°åœ¨å¯ä»¥é€šè¿‡ç½‘ç«™ç•Œé¢æäº¤ç ”ç©¶è¯·æ±‚ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä¸ºå…¶åˆ›å»ºç‹¬ç«‹çš„å·¥ä½œç¯å¢ƒï¼Œå¹¶ä¿å­˜æ‰€æœ‰ç ”ç©¶æˆæœåœ¨ç”¨æˆ·ä¸“å±ç›®å½•ä¸­ã€‚ç”¨æˆ·å¯ä»¥éšæ—¶æŸ¥çœ‹ç ”ç©¶è¿›åº¦ã€ä¸‹è½½æŠ¥å‘Šå’Œå›¾è¡¨ï¼Œè€Œæ— éœ€æ‹…å¿ƒä¸å…¶ä»–ç”¨æˆ·çš„æ•°æ®æ··æ·†ã€‚

# AgentLaboratory WebæœåŠ¡å™¨é›†æˆ

æœ¬é¡¹ç›®å®ç°äº†AgentLaboratoryç ”ç©¶è‡ªåŠ¨åŒ–æ¡†æ¶ä¸WebæœåŠ¡å™¨çš„é›†æˆï¼Œä½¿ç”¨æˆ·å¯ä»¥é€šè¿‡Webç•Œé¢è½»æ¾å¯åŠ¨å’Œç®¡ç†è‡ªåŠ¨åŒ–ç ”ç©¶ä»»åŠ¡ã€‚

## ä¸»è¦åŠŸèƒ½

- é€šè¿‡Webç•Œé¢ç®¡ç†ç ”ç©¶ä»»åŠ¡
- æ”¯æŒå¤šç§è¯­è¨€çš„ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ
- ç”¨æˆ·æ•°æ®ç®¡ç†å’Œä¼šè¯æ§åˆ¶
- è®ºæ–‡ä¸Šä¼ å’Œæœç´¢åŠŸèƒ½
- ç ”ç©¶ç»“æœå¯è§†åŒ–å’Œå…±äº«
- ä¸AgentRxivé›†æˆï¼Œæ”¯æŒè‡ªä¸»ç ”ç©¶ä»£ç†ä¹‹é—´çš„åä½œ

## è®ºæ–‡ç‰ˆæœ¬è‡ªåŠ¨åˆ‡æ¢åŠŸèƒ½

ä¸ºäº†æé«˜è®ºæ–‡è·å–çš„æˆåŠŸç‡ï¼Œç³»ç»Ÿç°åœ¨æ”¯æŒåœ¨è®ºæ–‡æŸ¥è¯¢å¤±è´¥æ—¶è‡ªåŠ¨å°è¯•è·å–åŒä¸€è®ºæ–‡çš„ä¸åŒç‰ˆæœ¬ã€‚

### ä¸»è¦ç‰¹æ€§ï¼š

1. **è‡ªåŠ¨ç‰ˆæœ¬åˆ‡æ¢**ï¼š
   - å½“è®ºæ–‡æŸ¥è¯¢è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°(5æ¬¡)åä»ç„¶å¤±è´¥æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°è¯•æŸ¥è¯¢åŒä¸€è®ºæ–‡çš„å…¶ä»–ç‰ˆæœ¬
   - æ”¯æŒåœ¨å¸¦ç‰ˆæœ¬å·çš„è®ºæ–‡ID(å¦‚1611.05431v3)å’Œä¸å¸¦ç‰ˆæœ¬å·çš„IDä¹‹é—´æ™ºèƒ½åˆ‡æ¢

2. **ç‰ˆæœ¬éå†**ï¼š
   - å¯¹äºå¸¦ç‰ˆæœ¬å·çš„è®ºæ–‡IDï¼Œç³»ç»Ÿä¼šå°è¯•v1åˆ°v5çš„æ‰€æœ‰ç‰ˆæœ¬
   - å¯¹äºä¸å¸¦ç‰ˆæœ¬å·çš„è®ºæ–‡IDï¼Œç³»ç»Ÿä¼šå°è¯•æ·»åŠ v1åç¼€è¿›è¡ŒæŸ¥è¯¢

3. **é”™è¯¯å¤„ç†ä¼˜åŒ–**ï¼š
   - é’ˆå¯¹å¸¸è§çš„è®ºæ–‡è·å–é”™è¯¯(å¦‚"object has no attribute 'updated_parsed'")æä¾›äº†è§£å†³æ–¹æ¡ˆ
   - å‡å°‘å› ç‰¹å®šç‰ˆæœ¬ä¸å¯ç”¨å¯¼è‡´çš„ç ”ç©¶ä¸­æ–­

4. **ç”¨æˆ·å‹å¥½æç¤º**ï¼š
   - å½“æˆåŠŸè·å–åˆ°æ›¿ä»£ç‰ˆæœ¬æ—¶ï¼Œç³»ç»Ÿä¼šæ¸…æ™°æ ‡æ˜åŸå§‹ç‰ˆæœ¬å’Œæ›¿ä»£ç‰ˆæœ¬ä¿¡æ¯
   - æä¾›è¯¦ç»†çš„é”™è¯¯æ—¥å¿—ï¼Œä¾¿äºé—®é¢˜æ’æŸ¥

è¿™ä¸€åŠŸèƒ½æ˜¾è‘—æé«˜äº†ç³»ç»Ÿè·å–ç ”ç©¶è®ºæ–‡çš„ç¨³å®šæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†arXivä¸Šçš„è®ºæ–‡æ—¶ï¼Œç¡®ä¿ç ”ç©¶æµç¨‹ä¸ä¼šå› å•ä¸ªè®ºæ–‡ç‰ˆæœ¬çš„è·å–é—®é¢˜è€Œä¸­æ–­ã€‚

## æŠ€æœ¯æ”¹è¿›

### é…ç½®æ•´åˆ

æˆ‘ä»¬å¯¹`app.py`è¿›è¡Œäº†ä¿®æ”¹ï¼Œæ•´åˆäº†`ai_lab_repo.py`ä¸­çš„é…ç½®é€»è¾‘ï¼Œä¸»è¦åŒ…æ‹¬ï¼š

1. æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒï¼Œå…è®¸ç”¨æˆ·æŒ‡å®šç«¯å£å’Œé…ç½®æ–‡ä»¶ï¼š
   ```python
   parser = argparse.ArgumentParser(description="AgentLaboratory Web Server")
   parser.add_argument('--port', type=int, default=5000, help='WebæœåŠ¡å™¨ç›‘å¬ç«¯å£')
   parser.add_argument('--yaml-location', type=str, default="experiment_configs/MATH_agentlab.yaml", help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºåŠ è½½é»˜è®¤é…ç½®')
   ```

2. ä»YAMLé…ç½®æ–‡ä»¶åŠ è½½é»˜è®¤è®¾ç½®ï¼Œå¹¶å­˜å‚¨åœ¨app.configä¸­ï¼š
   ```python
   app.config['DEFAULT_LLM_BACKBONE'] = config.get('llm-backend', "o4-mini-yunwu")
   app.config['DEFAULT_LANGUAGE'] = config.get('language', 'ä¸­æ–‡')
   app.config['DEFAULT_NUM_PAPERS_LIT_REVIEW'] = config.get('num-papers-lit-review', 5)
   # æ›´å¤šé…ç½®...
   ```

3. æ”¯æŒAPIå¯†é’¥çš„ç¯å¢ƒå˜é‡è®¾ç½®ï¼š
   ```python
   api_key = config.get('api-key')
   if api_key and not os.environ.get('OPENAI_API_KEY'):
       os.environ['OPENAI_API_KEY'] = api_key
   ```

### AgentRxivæ”¯æŒ

ä¸ºäº†æ”¯æŒAgentRxivåŠŸèƒ½ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä»¥ä¸‹æ”¹è¿›ï¼š

1. ä¿®æ”¹äº†`AgentRxiv`ç±»ï¼Œä½¿å…¶èƒ½å¤Ÿæ¥å—ç«¯å£å‚æ•°ï¼š
   ```python
   def __init__(self, lab_index=0, port=None):
       self.port = port if port is not None else 5000 + self.lab_index
   ```

2. åœ¨`run_app`å‡½æ•°ä¸­åˆå§‹åŒ–å…¨å±€AgentRxivå®ä¾‹ï¼š
   ```python
   if AI_LAB_AVAILABLE:
       from ai_lab_repo import AgentRxiv
       import ai_lab_repo
       ai_lab_repo.GLOBAL_AGENTRXIV = AgentRxiv(lab_index=app.config.get('DEFAULT_LAB_INDEX', 0), port=port)
   ```

3. åœ¨`run_research_task`å‡½æ•°ä¸­ç¡®ä¿AgentRxivæ­£ç¡®åˆå§‹åŒ–ï¼š
   ```python
   if agentRxiv and not ai_lab_repo.GLOBAL_AGENTRXIV:
       lab_index = workflow_params.get('lab_index', 0)
       ai_lab_repo.GLOBAL_AGENTRXIV = AgentRxiv(lab_index=lab_index)
   ```

### ç ”ç©¶ä»»åŠ¡å¤„ç†æ”¹è¿›

æˆ‘ä»¬å¯¹`run_research_task`å‡½æ•°è¿›è¡Œäº†å…¨é¢æ”¹è¿›ï¼š

1. ä½¿ç”¨app.configä¸­çš„é»˜è®¤å€¼ä½œä¸ºé…ç½®å›é€€ï¼š
   ```python
   if 'num-papers-lit-review' in config:
       workflow_params['num_papers_lit_review'] = config['num-papers-lit-review']
   elif 'DEFAULT_NUM_PAPERS_LIT_REVIEW' in app.config:
       workflow_params['num_papers_lit_review'] = app.config['DEFAULT_NUM_PAPERS_LIT_REVIEW']
   ```

2. æ”¹è¿›äº†ä»»åŠ¡ç¬”è®°çš„å¤„ç†é€»è¾‘ï¼Œæ”¯æŒå¤šè¯­è¨€ï¼š
   ```python
   # å¤„ç†ä»»åŠ¡ç¬”è®°ï¼Œè½¬æ¢ä¸ºLaboratoryWorkflowå¯æ¥å—çš„æ ¼å¼
   task_notes_LLM = []
   task_notes = config['task-notes']
   
   # æ”¶é›†æ‰€æœ‰å®é™…æ¶‰åŠçš„ä»»åŠ¡é˜¶æ®µ
   phases_in_notes = set()
   
   for _task in task_notes:
       readable_phase = _task.replace("-", " ")
       phases_in_notes.add(readable_phase)
       for _note in task_notes[_task]:
           task_notes_LLM.append({"phases": [readable_phase], "note": _note})
   ```

3. æ·»åŠ äº†agentæ¨¡å‹é…ç½®ï¼š
   ```python
   llm_backend = config.get('llm-backend', app.config.get('DEFAULT_LLM_BACKBONE', 'o4-mini-yunwu'))
   agent_models = {
       "literature review": llm_backend,
       "plan formulation": llm_backend,
       # æ›´å¤šé˜¶æ®µ...
   }
   workflow_params['agent_model_backbone'] = agent_models
   ```

## ä½¿ç”¨æ–¹æ³•

å¯åŠ¨æœåŠ¡å™¨ï¼š
```bash
python app.py --port 5000 --yaml-location "experiment_configs/MATH_agentlab.yaml"
```

è®¿é—®Webç•Œé¢ï¼š
```
http://localhost:5000
```

## æ³¨æ„äº‹é¡¹

- ç¡®ä¿å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„ä¾èµ–é¡¹
- åœ¨å¯ç”¨AgentRxivåŠŸèƒ½æ—¶ï¼Œç¡®ä¿æœåŠ¡å™¨åœ¨æ­£ç¡®çš„ç«¯å£ä¸Šè¿è¡Œ
- å¯¹äºéè‹±è¯­ç ”ç©¶ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®é€‚å½“çš„è¯­è¨€å‚æ•°

# å¤šç”¨æˆ·ç¯å¢ƒä¸‹çš„æ–‡ä»¶è·¯å¾„ä¿®å¤

æœ¬æ¬¡ä¿®æ”¹è§£å†³äº†å¤šç”¨æˆ·ç¯å¢ƒä¸‹æ–‡ä»¶ä¿å­˜è·¯å¾„çš„é—®é¢˜ï¼Œç¡®ä¿æ¯ä¸ªç”¨æˆ·çš„æ–‡ä»¶éƒ½ä¿å­˜åœ¨å„è‡ªçš„é¡¹ç›®ç›®å½•ä¸­ï¼Œè€Œä¸æ˜¯ä¿å­˜åœ¨æ ¹ç›®å½•ã€‚

## ä¸»è¦ä¿®æ”¹

1. **å·¥ä½œç›®å½•åˆ‡æ¢**
   - åœ¨ `worker_run_code` å‡½æ•°ä¸­æ·»åŠ äº†å·¥ä½œç›®å½•åˆ‡æ¢é€»è¾‘ï¼Œç¡®ä¿ä»£ç æ‰§è¡Œæ—¶ä½¿ç”¨ç”¨æˆ·çš„é¡¹ç›®ç›®å½•ä½œä¸ºå½“å‰å·¥ä½œç›®å½•
   - æ·»åŠ äº†æ¢å¤åŸå§‹å·¥ä½œç›®å½•çš„é€»è¾‘ï¼Œç¡®ä¿æ‰§è¡Œç»“æŸåæ¢å¤ç³»ç»ŸçŠ¶æ€

2. **æ–‡ä»¶è·¯å¾„å¤„ç†**
   - ä¿®æ”¹äº† `save_to_file` å‡½æ•°ï¼Œå¤„ç†ç›¸å¯¹è·¯å¾„å‰ç¼€ï¼Œç¡®ä¿æ–‡ä»¶ä¿å­˜åœ¨æ­£ç¡®çš„ä½ç½®
   - åœ¨ `worker_run_code` å‡½æ•°ä¸­æ·»åŠ äº†æ–‡ä»¶è·¯å¾„å¤„ç†é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
     - é‡å®šå‘ `open` å‡½æ•°ï¼Œç¡®ä¿ç›¸å¯¹è·¯å¾„çš„æ–‡ä»¶æ“ä½œåœ¨ç”¨æˆ·ç›®å½•ä¸­è¿›è¡Œ
     - æ·»åŠ  `ensure_user_path` è¾…åŠ©å‡½æ•°ï¼Œç”¨äºå¤„ç†å„ç§æ–‡ä»¶è·¯å¾„
     - æ›¿æ¢å¸¸è§çš„æ–‡ä»¶æ“ä½œæ¨¡å¼ï¼Œå¦‚ `plt.savefig`ã€`with open`ã€`.to_csv` ç­‰

3. **ä¿®æ­£ç›¸å¯¹è·¯å¾„ä½¿ç”¨**
   - ä¿®æ”¹äº† `ai_lab_repo.py` ä¸­çš„ `save_to_file` è°ƒç”¨ï¼Œå»æ‰äº†ç›¸å¯¹è·¯å¾„å‰ç¼€ `./`
   - ä½¿ç”¨ `os.path.join` æ„å»ºæ–‡ä»¶è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„åˆ†éš”ç¬¦çš„æ­£ç¡®æ€§å’Œå¹³å°å…¼å®¹æ€§

## æ•ˆæœ

è¿™äº›ä¿®æ”¹ç¡®ä¿äº†ï¼š

1. æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬å›¾åƒã€æ•°æ®æ–‡ä»¶ç­‰ï¼‰éƒ½ä¿å­˜åœ¨ç”¨æˆ·çš„é¡¹ç›®ç›®å½•ä¸­
2. å³ä½¿ä»£ç ä¸­ä½¿ç”¨äº†ç›¸å¯¹è·¯å¾„ï¼Œä¹Ÿä¼šè¢«é‡å®šå‘åˆ°ç”¨æˆ·çš„é¡¹ç›®ç›®å½•
3. ä¸åŒç”¨æˆ·çš„æ–‡ä»¶ä¸ä¼šç›¸äº’å¹²æ‰°

è¿™ä½¿å¾—ç³»ç»Ÿå¯ä»¥å®‰å…¨åœ°åœ¨å¤šç”¨æˆ·ç¯å¢ƒä¸­è¿è¡Œï¼Œæ¯ä¸ªç”¨æˆ·çš„ç ”ç©¶é¡¹ç›®éƒ½æœ‰è‡ªå·±ç‹¬ç«‹çš„æ–‡ä»¶ç©ºé—´ã€‚

# ä¿®å¤çŠ¶æ€ä¿å­˜åºåˆ—åŒ–é—®é¢˜

æœ¬æ¬¡ä¿®æ”¹è§£å†³äº†åœ¨ä¿å­˜ç ”ç©¶çŠ¶æ€æ—¶å‡ºç°çš„ "Can't pickle local object 'run_research_task.<locals>.<lambda>'" é”™è¯¯ã€‚

## é—®é¢˜æè¿°

åœ¨å¤šç”¨æˆ·ç¯å¢ƒä¸‹ï¼Œç³»ç»Ÿä½¿ç”¨ pickle æ¨¡å—æ¥åºåˆ—åŒ–å’Œä¿å­˜ç ”ç©¶ä»»åŠ¡çš„çŠ¶æ€ï¼Œä»¥ä¾¿åœ¨éœ€è¦æ—¶æ¢å¤ã€‚ç„¶è€Œï¼Œå½“ç ”ç©¶ä»»åŠ¡ä¸­åŒ…å«å±€éƒ¨å®šä¹‰çš„ lambda å‡½æ•°ä½œä¸ºå›è°ƒæ—¶ï¼Œpickle æ— æ³•åºåˆ—åŒ–è¿™äº›å‡½æ•°ï¼Œå¯¼è‡´çŠ¶æ€ä¿å­˜å¤±è´¥ã€‚

## è§£å†³æ–¹æ¡ˆ

1. **åˆ›å»ºå…¨å±€å›è°ƒåŒ…è£…å™¨**ï¼š
   - æ·»åŠ äº† `state_callback_wrapper` å‡½æ•°ï¼Œå®ƒæ¥æ”¶ `task_id` å‚æ•°å¹¶è¿”å›ä¸€ä¸ªå¯åºåˆ—åŒ–çš„å›è°ƒå‡½æ•°
   - è¿™ä¸ªåŒ…è£…å™¨å‡½æ•°åœ¨æ¨¡å—çº§åˆ«å®šä¹‰ï¼Œè€Œä¸æ˜¯åœ¨å‡½æ•°å†…éƒ¨å®šä¹‰ï¼Œå› æ­¤å¯ä»¥è¢« pickle åºåˆ—åŒ–

2. **æ›¿æ¢ lambda å‡½æ•°**ï¼š
   - å°† `run_research_task` å‡½æ•°ä¸­çš„ lambda è¡¨è¾¾å¼æ›¿æ¢ä¸ºå¯¹ `state_callback_wrapper` çš„è°ƒç”¨
   - å°† `continue_research_task` å‡½æ•°ä¸­çš„ lambda è¡¨è¾¾å¼ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„æ›¿æ¢

3. **ä¿æŒå‚æ•°ä¼ é€’**ï¼š
   - é€šè¿‡é—­åŒ…æœºåˆ¶ï¼Œ`state_callback_wrapper` è¿”å›çš„å‡½æ•°ä»ç„¶å¯ä»¥è®¿é—® `task_id` å‚æ•°
   - è¿”å›çš„å‡½æ•°ç­¾åä¸åŸå§‹ lambda å‡½æ•°ç›¸åŒï¼Œä¿æŒäº†æ¥å£çš„ä¸€è‡´æ€§

## æ•ˆæœ

è¿™äº›ä¿®æ”¹ç¡®ä¿äº†ï¼š

1. ç ”ç©¶ä»»åŠ¡çŠ¶æ€å¯ä»¥æ­£ç¡®åºåˆ—åŒ–å’Œä¿å­˜
2. ç”¨æˆ·å¯ä»¥æš‚åœå’Œæ¢å¤ç ”ç©¶ä»»åŠ¡è€Œä¸ä¼šé‡åˆ°åºåˆ—åŒ–é”™è¯¯
3. å›è°ƒå‡½æ•°ä»ç„¶èƒ½å¤Ÿæ­£ç¡®åœ°å°†çŠ¶æ€ä¿å­˜äº‹ä»¶é€šçŸ¥ç»™æ•°æ®åº“

è¿™ä¸€æ”¹è¿›å¢å¼ºäº†ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨é•¿æ—¶é—´è¿è¡Œçš„ç ”ç©¶ä»»åŠ¡ä¸­ï¼Œç”¨æˆ·å¯ä»¥å®‰å…¨åœ°æš‚åœå’Œæ¢å¤ä»»åŠ¡ï¼Œè€Œä¸ä¼šä¸¢å¤±è¿›åº¦ã€‚

## Code Execution Mechanism Optimization

To improve system transparency and debuggability, we have optimized the code execution mechanism. The main improvements include:

### Improvements

1. **Code File Saving**: The system now first saves the generated code to a `generated_code.py` file in the user's project folder before executing it, rather than directly executing the code string in memory.

2. **Execution Transparency**: Users can view and modify the generated code file before or after execution, enhancing the system's transparency and controllability.

3. **Debugging Convenience**: By saving the code to a file, users can more easily debug and modify AI-generated code, especially in complex experiments and data processing tasks.

4. **Enhanced Execution Results**: The `execute_code` function now returns richer information, including execution output and code file path, making it easier for users to perform further operations.

### Effects

1. **Enhanced Visibility**: Users can directly view the AI-generated code instead of treating it as a black box execution.

2. **Simplified Debugging Process**: When code execution fails, users can directly view and modify the saved code file without having to extract code snippets from error messages.

3. **Improved User Control**: Users can review the generated code before execution, enhancing the system's controllability and security.

4. **Support for Iterative Development**: Users can iteratively develop based on AI-generated code, further improving experimental results.

This optimization provides a better user experience and higher transparency while maintaining automation, particularly suitable for research scenarios requiring fine-grained control and debugging.

## Fixed Code Execution Return Value Handling

To address potential type errors in the code execution process, we have further optimized the code execution mechanism:

### Improvements

1. **Unified Return Format**: Modified the `execute_code` function to ensure a consistent dictionary format is returned in all cases (including error cases), containing `output` and `code_file` fields.

2. **Enhanced Robustness**: Added more comprehensive type checking and handling in the `run_code` method of `mlesolver.py`, capable of correctly processing various possible return value types.

3. **Backward Compatibility**: Maintained compatibility with older versions that directly return string formats, ensuring smooth transitions during system upgrades.

### Effects

1. **Avoided Type Errors**: Resolved the `TypeError: string indices must be integers, not 'str'` error caused by inconsistent return value formats.

2. **Improved Stability**: Enhanced system stability in various execution environments, especially when handling error situations.

3. **Better User Experience**: Reduced task failures due to internal errors, improving the completion rate of user research tasks.

This fix ensures that the code execution mechanism works properly in all scenarios, enhancing the overall stability and reliability of the system.

## Optimized Task Status Display

To enhance user experience and provide more timely system feedback, we have optimized the task status display mechanism:

### Improvements

1. **Immediate Status Updates**: Modified the task creation logic to display tasks as "running" immediately after submission, rather than the default "pending" status.

2. **Eliminated Status Delays**: Removed redundant status update operations in background threads, ensuring status changes are immediately reflected to users.

3. **Streamlined Process**: Simplified the status update workflow, reducing unnecessary database operations.

### Effects

1. **Enhanced User Experience**: Users can immediately see that their task has started executing, reducing uncertainty during wait times.

2. **More Accurate Status Feedback**: System status displays more accurately reflect the actual task execution state.

3. **Reduced User Confusion**: Prevents confusion and duplicate submissions that might occur when tasks remain in "pending" status for extended periods.

This optimization makes system status feedback more timely and accurate, improving the overall user experience.